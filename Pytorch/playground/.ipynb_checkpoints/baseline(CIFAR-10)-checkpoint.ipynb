{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a552b95f-9d2d-4ceb-a11d-0b49816f739a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bumchanpark/anaconda3/envs/bumchan/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4edd05a-23b2-4ec6-8aeb-d909f14d0b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) CIFAR-10 전처리 (컬러 3채널, 32x32)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465],  # CIFAR-10 통계값\n",
    "        std=[0.2470, 0.2435, 0.2616]\n",
    "    ),\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465],\n",
    "        std=[0.2470, 0.2435, 0.2616]\n",
    "    ),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d95d27db-3dd6-4e81-8d47-f42fa851f363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:30<00:00, 5608462.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-10-python.tar.gz to data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 2) CIFAR-10 데이터셋 로드\n",
    "training_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform,\n",
    ")\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transform,\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c07e46c5-bb8d-44b1-96db-c4bc32b1461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) DataLoader 생성\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(\n",
    "    training_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9936e5d-639a-49c2-b48c-cea2bec32cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Baseline 모델 정의\n",
    "class CIFAR10Baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(3 * 32 * 32, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return self.linear_relu_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d76f19cc-da78-48da-a31a-284c47e1d988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 5) 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = CIFAR10Baseline().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f40c52c3-3a62-4691-9433-79e26135b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) 손실함수 & 옵티마이저\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "469408b8-6c12-4080-9d78-b9a3118424ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) 학습 함수\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # 순전파\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 로깅\n",
    "        if batch % 100 == 0:\n",
    "            current = batch * len(X)\n",
    "            print(f\"  [Train] loss: {loss.item():>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cfc30cd-ce27-4874-bf52-3d58c98a3677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) 평가 함수\n",
    "def test(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    accuracy = correct / size * 100\n",
    "    print(f\"  [Test]  Accuracy: {accuracy:>5.2f}% | Avg loss: {test_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8e508d6-952c-410e-97de-e92c72c155cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Epoch 1/5 ===\n",
      "  [Train] loss: 2.291951  [    0/50000]\n",
      "  [Train] loss: 2.137843  [ 6400/50000]\n",
      "  [Train] loss: 2.088765  [12800/50000]\n",
      "  [Train] loss: 1.874971  [19200/50000]\n",
      "  [Train] loss: 1.844777  [25600/50000]\n",
      "  [Train] loss: 1.792764  [32000/50000]\n",
      "  [Train] loss: 1.801580  [38400/50000]\n",
      "  [Train] loss: 1.775653  [44800/50000]\n",
      "  [Test]  Accuracy: 40.61% | Avg loss: 1.683498\n",
      "\n",
      "=== Epoch 2/5 ===\n",
      "  [Train] loss: 1.807454  [    0/50000]\n",
      "  [Train] loss: 1.641751  [ 6400/50000]\n",
      "  [Train] loss: 1.739317  [12800/50000]\n",
      "  [Train] loss: 1.743531  [19200/50000]\n",
      "  [Train] loss: 1.719878  [25600/50000]\n",
      "  [Train] loss: 1.563154  [32000/50000]\n",
      "  [Train] loss: 1.585957  [38400/50000]\n",
      "  [Train] loss: 1.531606  [44800/50000]\n",
      "  [Test]  Accuracy: 46.27% | Avg loss: 1.549692\n",
      "\n",
      "=== Epoch 3/5 ===\n",
      "  [Train] loss: 1.543652  [    0/50000]\n",
      "  [Train] loss: 1.425992  [ 6400/50000]\n",
      "  [Train] loss: 1.360941  [12800/50000]\n",
      "  [Train] loss: 1.514956  [19200/50000]\n",
      "  [Train] loss: 1.460507  [25600/50000]\n",
      "  [Train] loss: 1.464621  [32000/50000]\n",
      "  [Train] loss: 1.370779  [38400/50000]\n",
      "  [Train] loss: 1.559042  [44800/50000]\n",
      "  [Test]  Accuracy: 48.21% | Avg loss: 1.480261\n",
      "\n",
      "=== Epoch 4/5 ===\n",
      "  [Train] loss: 1.405430  [    0/50000]\n",
      "  [Train] loss: 1.373392  [ 6400/50000]\n",
      "  [Train] loss: 1.512589  [12800/50000]\n",
      "  [Train] loss: 1.500581  [19200/50000]\n",
      "  [Train] loss: 1.505152  [25600/50000]\n",
      "  [Train] loss: 1.435344  [32000/50000]\n",
      "  [Train] loss: 1.448663  [38400/50000]\n",
      "  [Train] loss: 1.436893  [44800/50000]\n",
      "  [Test]  Accuracy: 49.44% | Avg loss: 1.432552\n",
      "\n",
      "=== Epoch 5/5 ===\n",
      "  [Train] loss: 1.789088  [    0/50000]\n",
      "  [Train] loss: 1.378591  [ 6400/50000]\n",
      "  [Train] loss: 1.413199  [12800/50000]\n",
      "  [Train] loss: 1.378662  [19200/50000]\n",
      "  [Train] loss: 1.335531  [25600/50000]\n",
      "  [Train] loss: 1.193584  [32000/50000]\n",
      "  [Train] loss: 1.479873  [38400/50000]\n",
      "  [Train] loss: 1.327731  [44800/50000]\n",
      "  [Test]  Accuracy: 51.23% | Avg loss: 1.395049\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# 9) 학습 루프\n",
    "epochs = 5\n",
    "for epoch in range(1, epochs + 1):\n",
    "    print(f\"\\n=== Epoch {epoch}/{epochs} ===\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee3dbc2-422d-4606-a0b8-87fc8b0edcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) 모델 저장\n",
    "torch.save(model.state_dict(), \"cifar10_baseline.pth\")\n",
    "print(\"Saved model to cifar10_baseline.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1611d56-80fc-4c79-9b53-1040c9a6eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) 모델 불러오기 & 예측 확인\n",
    "model = CIFAR10Baseline().to(device)\n",
    "model.load_state_dict(torch.load(\"cifar10_baseline.pth\"))\n",
    "model.eval()\n",
    "\n",
    "classes = [\n",
    "    \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
    "]\n",
    "\n",
    "# 테스트 데이터셋의 첫 샘플로 예측 예시\n",
    "x, y_true = test_data[0]\n",
    "x = x.to(device).unsqueeze(0)  # 배치 차원 추가\n",
    "with torch.no_grad():\n",
    "    logits = model(x)\n",
    "    y_pred = logits.argmax(1).item()\n",
    "\n",
    "print(f'Predicted: \"{classes[y_pred]}\", Actual: \"{classes[y_true]}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
